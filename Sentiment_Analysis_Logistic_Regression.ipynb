{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "slideshow": {
     "slide_type": "skip"
    }
   },
   "outputs": [],
   "source": [
    "from matplotlib import pyplot as plt\n",
    "import numpy as np\n",
    "from math import exp\n",
    "from PIL import Image\n",
    "import sklearn\n",
    "\n",
    "\n",
    "t = np.arange(-7, 7, 0.01)\n",
    "\n",
    "# red dashes, blue squares and green triangles\n",
    "plt.plot(t, 1/(1+(np.exp(-t))))\n",
    "plt.savefig('logistic.png')\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "Hi! This is a python notebook demoing using Logistic Regression for sentiment analysis on the public IMDB movie reviews dataset.\n",
    "\n",
    "Idea creds:\n",
    "https://towardsdatascience.com/sentiment-analysis-with-python-part-1-5ce197074184\n",
    "\n",
    "Dataset is available at:\n",
    "https://www.kaggle.com/iarunava/imdb-movie-reviews-dataset\n",
    "\n",
    "\n",
    "\n",
    "$${}$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "  * What is logistic regression and what is it used for?  \n",
    "      * Go-to for binary classification\n",
    "         * Binary classification is useful when we have 2 choices(b/w, y/n, good/bad)\n",
    "         * Not so useful when we don't have discrete choices ie. pretty good\n",
    "      * Like many machine learning techniques it was stolen from statistics\n",
    "          * At its core it uses the logistic function aka the sigmoid function\n",
    "          * Logistic function takes any real-valued number and maps it between 0 and 1  \n",
    "          # $ \\frac{1}{1+e^{-x}} \\quad \\forall x \\in \\mathbb{R}$\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "![](logistic.png) \n",
    "* We won't go into exactly how it works, but it essentially creates a plane that separates high dimensional data using maximum likelihood estimation(sklearn uses a numerical optimization algorithm.)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "  * Disadvantages and Advantages\n",
    "      * Disadvantages:\n",
    "          * Because it relies on feature vectors it can struggle with noise\n",
    "              * Can solve this by cleaning data\n",
    "          * Overfitting\n",
    "              * Get more data\n",
    "              * Regularization\n",
    "          * Bias\n",
    "              * Classic case is a rare disease\n",
    "              * Upsample or Downsample data\n",
    "          * Non-Convergence\n",
    "              * Clean data--check for highly correlated pts\n",
    "      * Advantages:\n",
    "          * Computationally efficient\n",
    "          * Easy to use\n",
    "          * Well documented and understood"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.21.2\n"
     ]
    }
   ],
   "source": [
    "#sckit_learn is a very well documented machine learning library. It's a little older than tf, but still very relevant.\n",
    "import sklearn\n",
    "print(sklearn.__version__)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [],
   "source": [
    "#load in the dataset\n",
    "train_reviews = []\n",
    "for line in open('full_train.txt', 'r'):\n",
    "    train_reviews.append(line.strip())\n",
    "    \n",
    "test_reviews = []\n",
    "for line in open('full_test.txt', 'r'):\n",
    "    test_reviews.append(line.strip())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Bromwell High is a cartoon comedy. It ran at the same time as some other programs about school life, such as \"Teachers\". My 35 years in the teaching profession lead me to believe that Bromwell High's satire is much closer to reality than is \"Teachers\". The scramble to survive financially, the insightful students who can see right through their pathetic teachers' pomp, the pettiness of the whole situation, all remind me of the schools I knew and their students. When I saw the episode in which a student repeatedly tried to burn down the school, I immediately recalled ......... at .......... High. A classic line: INSPECTOR: I'm here to sack one of your teachers. STUDENT: Welcome to Bromwell High. I expect that many adults of my age think that Bromwell High is far fetched. What a pity that it isn't!\n"
     ]
    }
   ],
   "source": [
    "print(train_reviews[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [],
   "source": [
    "import re\n",
    "\n",
    "REPLACE_NO_SPACE = re.compile(\"[.;:!\\'?,\\\"()\\[\\]]\")\n",
    "REPLACE_WITH_SPACE = re.compile(\"(<br\\s*/><br\\s*/>)|(\\-)|(\\/)\")\n",
    "\n",
    "def preprocess_reviews(reviews):\n",
    "    reviews = [REPLACE_NO_SPACE.sub(\"\", line.lower()) for line in reviews]\n",
    "    reviews = [REPLACE_WITH_SPACE.sub(\" \", line) for line in reviews]\n",
    "    \n",
    "    return reviews\n",
    "\n",
    "reviews_train_clean = preprocess_reviews(train_reviews)\n",
    "reviews_test_clean = preprocess_reviews(train_reviews)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "bromwell high is a cartoon comedy it ran at the same time as some other programs about school life such as teachers my 35 years in the teaching profession lead me to believe that bromwell highs satire is much closer to reality than is teachers the scramble to survive financially the insightful students who can see right through their pathetic teachers pomp the pettiness of the whole situation all remind me of the schools i knew and their students when i saw the episode in which a student repeatedly tried to burn down the school i immediately recalled  at  high a classic line inspector im here to sack one of your teachers student welcome to bromwell high i expect that many adults of my age think that bromwell high is far fetched what a pity that it isnt\n"
     ]
    }
   ],
   "source": [
    "print(reviews_train_clean[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [],
   "source": [
    "#here we map all reviews to a feature vector\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "\n",
    "cv = CountVectorizer(binary=True)\n",
    "cv.fit(reviews_train_clean)\n",
    "X = cv.transform(reviews_train_clean)\n",
    "X_test = cv.transform(reviews_test_clean)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [],
   "source": [
    "#here we'll actually train our logistiregression model\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "target = [1 if i < 12500 else 0 for i in range(25000)]\n",
    "X_train, X_val, y_train, y_val = train_test_split(X, target, train_size = 0.75)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/skandera/anaconda3/envs/tf/lib/python3.7/site-packages/sklearn/linear_model/logistic.py:432: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy for C=0.001: 0.85248\n",
      "Accuracy for C=0.01: 0.8792\n",
      "Accuracy for C=0.05: 0.88592\n",
      "Accuracy for C=0.25: 0.88432\n",
      "Accuracy for C=0.5: 0.88224\n",
      "Accuracy for C=1: 0.88112\n",
      "Accuracy for C=2: 0.87888\n"
     ]
    }
   ],
   "source": [
    "#c=1/lambda and is part of the regularization term\n",
    "\n",
    "for c in [0.001, 0.01, 0.05, 0.25, 0.5, 1, 2]:  \n",
    "    lr = LogisticRegression(C=c)\n",
    "    lr.fit(X_train, y_train)\n",
    "    print (\"Accuracy for C=%s: %s\" \n",
    "           % (c, accuracy_score(y_val, lr.predict(X_val))))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Final Accuracy: 0.95148\n"
     ]
    }
   ],
   "source": [
    "best_model = LogisticRegression(C=0.05)\n",
    "best_model.fit(X, target)\n",
    "print (\"Final Accuracy: %s\" \n",
    "       % accuracy_score(target, best_model.predict(X_test)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "best positives:\n",
      "('excellent', 0.9292549055817553)\n",
      "('perfect', 0.7907005762467144)\n",
      "('great', 0.6745323564933414)\n",
      "('amazing', 0.6127039869748403)\n",
      "('superb', 0.6019367969264237)\n",
      "\n",
      " best negatives:\n",
      "('worst', -1.3645958793195605)\n",
      "('waste', -1.1664241934163166)\n",
      "('awful', -1.0324189239200765)\n",
      "('poorly', -0.8752018714482658)\n",
      "('boring', -0.8563543372884128)\n"
     ]
    }
   ],
   "source": [
    "feature_to_coef = {word: coef for word, coef in zip(\n",
    "        cv.get_feature_names(), best_model.coef_[0])}\n",
    "\n",
    "print('best positives:')\n",
    "for best_positive in sorted(feature_to_coef.items(), \n",
    "    key=lambda x: x[1], reverse=True)[:5]:\n",
    "    print (best_positive)\n",
    "    \n",
    "print('\\n best negatives:')   \n",
    "for best_negative in sorted(\n",
    "    feature_to_coef.items(), \n",
    "    key=lambda x: x[1])[:5]:\n",
    "    print (best_negative)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [],
   "source": [
    "noise=set(['if', 'for', 'and', 'in', 'of', 'at', 'the', 'is', 'i', 'a', 'it', 'is', 'that'])\n",
    "def remove_noise_words(corpus):\n",
    "    removed_noise_words = []\n",
    "    for review in corpus:\n",
    "        removed_noise_words.append(\n",
    "            ' '.join([word for word in review.split() \n",
    "                      if word not in noise]))\n",
    "    return removed_noise_words\n",
    "\n",
    "no_noise_words_train = remove_noise_words(reviews_train_clean)\n",
    "no_noise_words_test = remove_noise_words(reviews_test_clean)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "bromwell high cartoon comedy ran same time as some other programs about school life such as teachers my 35 years teaching profession lead me to believe bromwell highs satire much closer to reality than teachers scramble to survive financially insightful students who can see right through their pathetic teachers pomp pettiness whole situation all remind me schools knew their students when saw episode which student repeatedly tried to burn down school immediately recalled high classic line inspector im here to sack one your teachers student welcome to bromwell high expect many adults my age think bromwell high far fetched what pity isnt\n"
     ]
    }
   ],
   "source": [
    "print(no_noise_words_train[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [],
   "source": [
    "cv = CountVectorizer(binary=True)\n",
    "cv.fit(reviews_train_clean)\n",
    "X = cv.transform(reviews_train_clean)\n",
    "X_test = cv.transform(reviews_test_clean)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/skandera/anaconda3/envs/tf/lib/python3.7/site-packages/sklearn/linear_model/logistic.py:432: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy for C=0.001: 0.84048\n",
      "Accuracy for C=0.01: 0.86864\n",
      "Accuracy for C=0.05: 0.88016\n",
      "Accuracy for C=0.25: 0.88064\n",
      "Accuracy for C=0.5: 0.87776\n",
      "Accuracy for C=1: 0.87648\n",
      "Accuracy for C=2: 0.876\n"
     ]
    }
   ],
   "source": [
    "target = [1 if i < 12500 else 0 for i in range(25000)]\n",
    "\n",
    "X_train, X_val, y_train, y_val = train_test_split(\n",
    "                                X, target, train_size = 0.75)\n",
    "\n",
    "for c in [0.001, 0.01, 0.05, 0.25, 0.5, 1, 2]:\n",
    "    lr = LogisticRegression(C=c)\n",
    "    lr.fit(X_train, y_train)\n",
    "    print (\"Accuracy for C=%s: %s\" \n",
    "           % (c, accuracy_score(y_val, lr.predict(X_val))))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/skandera/anaconda3/envs/tf/lib/python3.7/site-packages/sklearn/linear_model/logistic.py:432: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy for C=0.01: 0.88512\n",
      "Accuracy for C=0.05: 0.892\n",
      "Accuracy for C=0.25: 0.89456\n",
      "Accuracy for C=0.5: 0.89584\n",
      "Accuracy for C=1: 0.896\n",
      "Accuracy for C=2: 0.89616\n"
     ]
    }
   ],
   "source": [
    "cv = CountVectorizer(binary=True, ngram_range=(1, 2))\n",
    "cv.fit(reviews_train_clean)\n",
    "X = cv.transform(reviews_train_clean)\n",
    "X_test = cv.transform(reviews_test_clean)\n",
    "\n",
    "\n",
    "target = [1 if i < 12500 else 0 for i in range(25000)]\n",
    "\n",
    "X_train, X_val, y_train, y_val = train_test_split(\n",
    "                                X, target, train_size = 0.75)\n",
    "\n",
    "for c in [0.01, 0.05, 0.25, 0.5, 1, 2]:\n",
    "    lr = LogisticRegression(C=c)\n",
    "    lr.fit(X_train, y_train)\n",
    "    print (\"Accuracy for C=%s: %s\" \n",
    "           % (c, accuracy_score(y_val, lr.predict(X_val))))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/skandera/anaconda3/envs/tf/lib/python3.7/site-packages/sklearn/linear_model/logistic.py:432: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy for C=0.01: 0.87952\n",
      "Accuracy for C=0.05: 0.8832\n",
      "Accuracy for C=0.25: 0.8848\n",
      "Accuracy for C=0.5: 0.88576\n",
      "Accuracy for C=1: 0.88624\n",
      "Accuracy for C=2: 0.8864\n",
      "Accuracy for C=100: 0.88432\n"
     ]
    }
   ],
   "source": [
    "cv = CountVectorizer(binary=True, ngram_range=(1, 5))\n",
    "cv.fit(reviews_train_clean)\n",
    "X = cv.transform(reviews_train_clean)\n",
    "X_test = cv.transform(reviews_test_clean)\n",
    "\n",
    "\n",
    "target = [1 if i < 12500 else 0 for i in range(25000)]\n",
    "\n",
    "X_train, X_val, y_train, y_val = train_test_split(\n",
    "                                X, target, train_size = 0.75)\n",
    "\n",
    "for c in [0.01, 0.05, 0.25, 0.5, 1, 2, 100]:\n",
    "    lr = LogisticRegression(C=c)\n",
    "    lr.fit(X_train, y_train)\n",
    "    print (\"Accuracy for C=%s: %s\" \n",
    "           % (c, accuracy_score(y_val, lr.predict(X_val))))\n",
    "#TODO add test"
   ]
  }
 ],
 "metadata": {
  "celltoolbar": "Slideshow",
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
